{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from  more_itertools import unique_everseen\n",
    "from collections import Counter\n",
    "\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "from training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>текст</th>\n",
       "      <th>бин тэги</th>\n",
       "      <th>тэги</th>\n",
       "      <th>текст анамнеза</th>\n",
       "      <th>is_med</th>\n",
       "      <th>is_food</th>\n",
       "      <th>is_env</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В году возобновление стенокардии при ФН, стаци...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>в год возобновление стенокардия при фн стацион...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>С г нарастание явлений ХСН до III ФК. Неоднокр...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>с год нарастание явление хсн до iii фк неоднок...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>г. прогрессирование клиники стенокардии до III...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>год прогрессирование клиника стенокардия до ii...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Состояние после оперативного лечения м. берцов...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>состояние после оперативный лечение метр берцо...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Начата аб терпия левофлоксацином, после перво...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>в год возобновление стенокардия при фн стацион...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               текст бин тэги тэги  \\\n",
       "0  В году возобновление стенокардии при ФН, стаци...        A    B   \n",
       "1  С г нарастание явлений ХСН до III ФК. Неоднокр...        A    B   \n",
       "2  г. прогрессирование клиники стенокардии до III...        A    B   \n",
       "3  Состояние после оперативного лечения м. берцов...        A    B   \n",
       "4   Начата аб терпия левофлоксацином, после перво...        A    B   \n",
       "\n",
       "                                      текст анамнеза  is_med  is_food  is_env  \\\n",
       "0  в год возобновление стенокардия при фн стацион...       1        0       0   \n",
       "1  с год нарастание явление хсн до iii фк неоднок...       1        0       0   \n",
       "2  год прогрессирование клиника стенокардия до ii...       1        0       0   \n",
       "3  состояние после оперативный лечение метр берцо...       1        0       0   \n",
       "4  в год возобновление стенокардия при фн стацион...       1        0       0   \n",
       "\n",
       "  Unnamed: 7  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "df = pd.read_csv('train_classif_norm_check.txt', sep='\\t',encoding='cp1251', engine='python', header=0, error_bad_lines=False)\n",
    "df_cat = pd.read_csv('train_check_no.txt', sep='\\t',encoding='cp1251', engine='python', header=0, error_bad_lines=False)\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>текст</th>\n",
       "      <th>бин тэги</th>\n",
       "      <th>пред бин тэги</th>\n",
       "      <th>тэги</th>\n",
       "      <th>текст анамнеза</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В году возобновление стенокардии при ФН, стаци...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>в год возобновление стенокардия при фн стацион...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ЛЖ, стац. лечение в ФЦ, тромболизис. ангинозны...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>лж стац лечение в фц тромболизис ангинозный бо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>РТСА со стентированием ПМЖА C без лекарственно...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>рт са с стентирование пмж c без лекарственный ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>С. г. переносит острый бронхит, проводилась ан...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>с год переносить острый бронхит проводиться ан...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Стац. лечение по мж с представлением о повторн...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>стац лечение по мж с представление о повторный...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               текст бин тэги пред бин тэги  \\\n",
       "0  В году возобновление стенокардии при ФН, стаци...        A             A   \n",
       "1  ЛЖ, стац. лечение в ФЦ, тромболизис. ангинозны...        C             C   \n",
       "2  РТСА со стентированием ПМЖА C без лекарственно...        C             C   \n",
       "3  С. г. переносит острый бронхит, проводилась ан...        C             C   \n",
       "4  Стац. лечение по мж с представлением о повторн...        C             C   \n",
       "\n",
       "  тэги                                     текст анамнеза  \n",
       "0    B  в год возобновление стенокардия при фн стацион...  \n",
       "1    D  лж стац лечение в фц тромболизис ангинозный бо...  \n",
       "2    D  рт са с стентирование пмж c без лекарственный ...  \n",
       "3    D  с год переносить острый бронхит проводиться ан...  \n",
       "4    C  стац лечение по мж с представление о повторный...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество категорий аллергии на запись:\n",
      " 1    7741\n",
      "2    1306\n",
      "3      93\n",
      "Name: num, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def f(a,b,c):\n",
    "    return a+b+c\n",
    "\n",
    "df_cat['num'] = df_cat.apply(lambda x: f(x.is_med, x.is_food, x.is_env), axis=1)\n",
    "\n",
    "df_cat_new = df_cat.loc[df_cat['num'] != 0]\n",
    "print('Количество категорий аллергии на запись:\\n',df_cat_new['num'].value_counts())\n",
    "\n",
    "df_cat_new['is_food'] = df_cat_new['is_food'].replace(1, 'A').replace(0, 'B')\n",
    "df_cat_new['is_env'] = df_cat_new['is_env'].replace(1, 'A').replace(0, 'B')\n",
    "df_cat_new['is_med'] = df_cat_new['is_med'].replace(1, 'A').replace(0, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фильтрация аллергоанамнезов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число уникальных слов 7272\n"
     ]
    }
   ],
   "source": [
    "#Подготовка данных\n",
    "train, val = train_test_split(df, test_size=0.33, random_state=42)\n",
    "X_train, y_train_cv = train['текст анамнеза'].values, train['бин тэги'].values\n",
    "X_val, y_val_cv = val['текст анамнеза'].values, val['бин тэги'].values\n",
    "\n",
    "#Создание словаря\n",
    "DICT_SIZE, WORDS_TO_INDEX, INDEX_TO_WORDS = make_dict(X_train, y_train_cv)\n",
    "\n",
    "from scipy import sparse as sp_sparse\n",
    "\n",
    "#Мешок слов\n",
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
    "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_val])\n",
    "\n",
    "#Подготовка и преобразование таргетов\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "tags_counts = Counter(chain.from_iterable([i for i in y_train_cv]))\n",
    "mlb = MultiLabelBinarizer(classes=sorted(tags_counts.keys()))\n",
    "y_train = mlb.fit_transform(y_train_cv)\n",
    "y_val = mlb.fit_transform(y_val_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score: 0.9431325301204819\n",
      "Precision: 0.9179327043112209\n",
      "Recall: 0.9073737096700849\n"
     ]
    }
   ],
   "source": [
    "model_lr = train_log_regression(X_train_mybag, y_train_cv)\n",
    "pred_lr = mlb.fit_transform(model_lr.predict(X_val_mybag))\n",
    "scores(y_val, pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag:\tA\n",
      "Top positive words:\tаллергоанамнез, пенициллин, престариум, анальгин, диротон, нитропрепарат, связь, аллергодерматит, ринит, аллергический, зуд, отечь, кашель, сыпь, аллергия, крапивница, плохой, непереносимость, аллергодерматить, нитрат\n",
      "Top negative words:\tдиувера, переноситься, подозрение, хорошо, нагрузка, быть, отмечать, особенность, удовлетворительный, перенос, физ, гипоаллергенный, субъективно, рча, фн, неаллергический, спокойный, отрица, нет, отрицать\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_AL_p, top_AL_n  = top_words(model_lr, 'A', mlb.classes, INDEX_TO_WORDS, WORDS_TO_INDEX.keys(),'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'allerg_classifier.sav'\n",
    "pickle.dump(model_lr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пищевая аллергия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число уникальных слов 5340\n"
     ]
    }
   ],
   "source": [
    "#Подготовка данных\n",
    "train, val = train_test_split(df_cat_new, test_size=0.33, random_state=42)\n",
    "X_train, y_train_cv = train['текст анамнеза'].values, train['is_food'].values\n",
    "X_val, y_val_cv = val['текст анамнеза'].values, val['is_food'].values\n",
    "\n",
    "#Создание словаря\n",
    "DICT_SIZE, WORDS_TO_INDEX, INDEX_TO_WORDS = make_dict(X_train, y_train_cv)\n",
    "\n",
    "from scipy import sparse as sp_sparse\n",
    "\n",
    "#Мешок слов\n",
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
    "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_val])\n",
    "\n",
    "#Подготовка и преобразование таргетов\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "tags_counts = Counter(chain.from_iterable([i for i in y_train_cv]))\n",
    "mlb = MultiLabelBinarizer(classes=sorted(tags_counts.keys()))\n",
    "y_train = mlb.fit_transform(y_train_cv)\n",
    "y_val = mlb.fit_transform(y_val_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score: 0.9532648326151807\n",
      "Precision: 0.9320814247932581\n",
      "Recall: 0.875682938746502\n"
     ]
    }
   ],
   "source": [
    "model_lr = train_log_regression(X_train_mybag, y_train_cv)\n",
    "pred_lr = mlb.fit_transform(model_lr.predict(X_val_mybag))\n",
    "scores(y_val, pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag:\tA\n",
      "Top positive words:\tмандарин, солодка, сорбифер, спирт, стоматология, орех, комаров, яйцо, алкоголь, красный, рыба, мед, стоматит, молоко, продукт, цитрусовый, лактоза, шоколад, пищевой, клубника\n",
      "Top negative words:\tкрапивница, гормон, аспирин, фолиевый, новокаин, смешанный, субкомпенсировать, лек, самостоятельно, пластырь, переносить, тироксин, пенициллин, отмечаться, пятно, лекарство, кура, эритромицин, поливалентный, сок\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_AL_p, top_AL_n  = top_words(model_lr, 'A', mlb.classes, INDEX_TO_WORDS, WORDS_TO_INDEX.keys(),'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'food_classifier.sav'\n",
    "pickle.dump(model_lr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Средовая аллергия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число уникальных слов 5340\n"
     ]
    }
   ],
   "source": [
    "#Подготовка данных\n",
    "train, val = train_test_split(df_cat_new, test_size=0.33, random_state=42)\n",
    "X_train, y_train_cv = train['текст анамнеза'].values, train['is_env'].values\n",
    "X_val, y_val_cv = val['текст анамнеза'].values, val['is_env'].values\n",
    "\n",
    "#Создание словаря\n",
    "DICT_SIZE, WORDS_TO_INDEX, INDEX_TO_WORDS = make_dict(X_train, y_train_cv)\n",
    "\n",
    "from scipy import sparse as sp_sparse\n",
    "\n",
    "#Мешок слов\n",
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
    "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_val])\n",
    "\n",
    "#Подготовка и преобразование таргетов\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "tags_counts = Counter(chain.from_iterable([i for i in y_train_cv]))\n",
    "mlb = MultiLabelBinarizer(classes=sorted(tags_counts.keys()))\n",
    "y_train = mlb.fit_transform(y_train_cv)\n",
    "y_val = mlb.fit_transform(y_val_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score: 0.9320517069937023\n",
      "Precision: 0.9026945310130232\n",
      "Recall: 0.8773299538605661\n"
     ]
    }
   ],
   "source": [
    "model_lr = train_log_regression(X_train_mybag, y_train_cv)\n",
    "pred_lr = mlb.fit_transform(model_lr.predict(X_val_mybag))\n",
    "scores(y_val, pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag:\tA\n",
      "Top positive words:\tсульфаниламидный, краситель, никотиновый, краска, магнезия, солнце, фотодерматоз, холод, укус, металл, поллиноз, пыльца, пыль, лейкопластырь, холодовый, цветение, шерсть, пластырь, сульфаниламид, бытовой\n",
      "Top negative words:\tинтоксикация, тонзиллэктомия, ацетилсалициловый, поливитамин, милдронат, переносить, фолиевый, тримекаин, ангионевротич, сторона, анафилактический, дигоксина, баралгин, сорный, канефрон, пятно, гептрал, книжный, красносодержащий, лекарство\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_AL_p, top_AL_n  = top_words(model_lr, 'A', mlb.classes, INDEX_TO_WORDS, WORDS_TO_INDEX.keys(),'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'env_classifier.sav'\n",
    "pickle.dump(model_lr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Медикаментозная аллергия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число уникальных слов 5340\n"
     ]
    }
   ],
   "source": [
    "#Подготовка данных\n",
    "train, val = train_test_split(df_cat_new, test_size=0.33, random_state=42)\n",
    "X_train, y_train_cv = train['текст анамнеза'].values, train['is_med'].values\n",
    "X_val, y_val_cv = val['текст анамнеза'].values, val['is_med'].values\n",
    "\n",
    "#Создание словаря\n",
    "DICT_SIZE, WORDS_TO_INDEX, INDEX_TO_WORDS = make_dict(X_train, y_train_cv)\n",
    "\n",
    "from scipy import sparse as sp_sparse\n",
    "\n",
    "#Мешок слов\n",
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
    "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_val])\n",
    "\n",
    "#Подготовка и преобразование таргетов\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "tags_counts = Counter(chain.from_iterable([i for i in y_train_cv]))\n",
    "mlb = MultiLabelBinarizer(classes=sorted(tags_counts.keys()))\n",
    "y_train = mlb.fit_transform(y_train_cv)\n",
    "y_val = mlb.fit_transform(y_val_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score: 0.9615512098110706\n",
      "Precision: 0.9438051241835982\n",
      "Recall: 0.9343467717688276\n"
     ]
    }
   ],
   "source": [
    "model_lr = train_log_regression(X_train_mybag, y_train_cv)\n",
    "pred_lr = mlb.fit_transform(model_lr.predict(X_val_mybag))\n",
    "scores(y_val, pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag:\tA\n",
      "Top positive words:\tаба, ампициллин, эуфиллина, бисептол, йодомарин, полиаллергия, димедрол, аспирин, пластырь, переносить, анальгин, лекарство, препарат, йод, бициллина, антибиотик, поливалентный, пенициллин, новокаин, медикамент\n",
      "Top negative words:\tдом, растение, шоколад, краска, зверобой, шерсть, поллиноз, глютен, аллерген, пищевой, клубника, металл, солнце, пыльца, пыль, укус, холодовый, фотодерматоз, холод, лактоза\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_AL_p, top_AL_n  = top_words(model_lr, 'A', mlb.classes, INDEX_TO_WORDS, WORDS_TO_INDEX.keys(),'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'med_classifier.sav'\n",
    "pickle.dump(model_lr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фильтрация реакций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число уникальных слов 5697\n"
     ]
    }
   ],
   "source": [
    "df_react = df.loc[df['бин тэги']=='A']\n",
    "\n",
    "#Подготовка данных\n",
    "train, val = train_test_split(df_react, test_size=0.33, random_state=42)\n",
    "X_train, y_train_cv = train['текст анамнеза'].values, train['тэги'].values\n",
    "X_val, y_val_cv = val['текст анамнеза'].values, val['тэги'].values\n",
    "\n",
    "#Создание словаря\n",
    "DICT_SIZE, WORDS_TO_INDEX, INDEX_TO_WORDS = make_dict(X_train, y_train_cv)\n",
    "\n",
    "from scipy import sparse as sp_sparse\n",
    "\n",
    "#Мешок слов\n",
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
    "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_val])\n",
    "\n",
    "#Подготовка и преобразование таргетов\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "tags_counts = Counter(chain.from_iterable([i for i in y_train_cv]))\n",
    "mlb = MultiLabelBinarizer(classes=sorted(tags_counts.keys()))\n",
    "y_train = mlb.fit_transform(y_train_cv)\n",
    "y_val = mlb.fit_transform(y_val_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = train_log_regression(X_train_mybag, y_train_cv)\n",
    "pred_lr = mlb.fit_transform(model_lr.predict(X_val_mybag))\n",
    "scores(y_val, pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_AL_p, top_AL_n  = top_words(model_lr, 'A', mlb.classes, INDEX_TO_WORDS, WORDS_TO_INDEX.keys(),'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'react_classifier.sav'\n",
    "pickle.dump(model_lr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
